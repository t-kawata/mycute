**記述長最小化原理 (MDL: Minimum Description Length Principle)** は、「オッカムの剃刀」を数学的に定式化した情報理論の概念です。一言で言えば、**「データを最も短いビット数で表現できるモデルこそが、本質を捉えた最適なモデルである」**という考え方です。

知識グラフの要約・ノイズ除去において、MDLは「どのノードを残し、どのノードを消すべきか」を判断する際の**“コスト関数”**として機能します。

### 1. MDLの基本概念
MDLでは、あるデータ（ここでは知識グラフ $G$）を記述するための「総情報量 $L(G)$」を以下の2つの和として定義し、これを最小化することを目指します。

$$L(G) = L(M) + L(D|M)$$

*   **$L(M)$：モデル記述長（Model Description Length）**
    *   **意味**: 知識グラフの「骨組み（構造）」を記述するのに必要な情報量。
    *   **グラフでの具体例**: 残されたノード数、エッジ数、およびそれらの定義情報。
    *   **傾向**: ノードを削除・統合してグラフを単純にするほど、この値は**小さく**なります。

*   **$L(D|M)$：データ記述長（Data Description Length）**
    *   **意味**: そのモデル（骨組み）を使って、元の詳細なデータを再現するのに必要な「補正情報（誤差）」の量。
    *   **グラフでの具体例**: 削除したノードやエッジが持っていた独自の具体情報や、統合によって失われた詳細な区別。
    *   **傾向**: ノードを削除しすぎると元の情報を復元できなくなるため、補正情報が増えてこの値は**大きく**なります。

### 2. 知識グラフ要約への応用プロセス
「孤立ノードを削除するかどうか」の判断は、以下のようなシミュレーションで行います。

1.  **仮説**: あるノード $n$ を削除（または隣接ノードと統合）したグラフモデル $M'$ を作る。
2.  **計算**:
    *   **コスト削減**: ノード $n$ 分のデータが減ったので、$L(M)$ がどれだけ減ったか計算する。
    *   **情報損失**: ノード $n$ が持っていた情報が失われたことで、他のノードから推測・復元するために必要な追加コスト $L(D|M)$ がどれだけ増えたか計算する。
3.  **判定**:
    *   **削除すべき（ノイズ/冗長）**: $L(M)$ の減少幅が $L(D|M)$ の増加幅より大きい場合。
        *   例：「AはBである」という単純な事実ノードで、Bの属性として表現すれば十分な場合。削除しても総記述長は減る（＝圧縮成功）。
    *   **残すべき（重要/特異点）**: $L(D|M)$ の増加幅が大きく、総記述長が増えてしまう場合。
        *   例：孤立しているが、「Xという極めて珍しい特性」を持つノード。これを削除すると、その特異な情報を説明するのに膨大な補足が必要になるため、ノードとして残す方が「安上がり」になる。

### 3. なぜこれが「合理的」なのか
*   **「孤立＝不要」の罠を回避**:
    MDLは「つながりの数（次数）」ではなく「情報のユニークさ（復元困難性）」を評価します。孤立していても、他に代えがたい情報を持つノードは、削除すると $L(D|M)$ が跳ね上がるため、数学的に「残すべき」と判定されます。
*   **「密度」の定義**:
    密度を単に「エッジ数÷ノード数」とするのではなく、「単位情報量あたりの意味の含有率」として捉え直します。MDL最小化は、同じ意味内容をより少ないノード・エッジで表現しようとする圧力として働くため、結果としてグラフは「濃縮」されます。

### 実装上のイメージ（Go/Kuzu）
実際には厳密なビット計算よりも、近似的なスコア計算を行います。

*   **Supernode化**: 似たような接続パターンや属性を持つ複数のノードを1つの「Supernode」にまとめる。
*   **エッジの集約**: A→B, A→C, A→D というエッジがあり、B,C,Dが似ているなら、A→{Group_BCD} という1本のエッジにまとめる。

この「まとめ作業」を行った前後でスコア（記述長）を比較し、スコアが良くなる（減る）なら変更を確定する、という貪欲法（Greedy Algorithm）的なアプローチでグラフを徐々に最適化します。

[1](https://www.jstage.jst.go.jp/article/essfr/10/3/10_186/_article/-char/ja/)
[2](http://www.sakurai.comp.ae.keio.ac.jp/classes/infosem-class/2014/14MDL.pdf)
[3](https://docs.oracle.com/cd/E15817_01/datamine.111/e05704/algo_mdl.htm)
[4](https://qiita.com/F-ridge/items/d67332ae1b0627b14f07)
[5](https://www.ibis.t.u-tokyo.ac.jp/yamanishi/kenkyunaiyou.html)
[6](https://ja.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E8%A8%98%E8%BF%B0%E9%95%B7)
[7](https://docs.oracle.com/cd/E57425_01/121/DMCON/GUID-96A38D67-2F09-4659-976D-4DDF478555E0.htm)
[8](https://www.jstage.jst.go.jp/article/jjsai/7/3/7_427/_pdf)
[9](https://ibisml.org/archive/ibisml001/2010_IBISML01_Hirai.pdf)
[10](https://www.me.inf.kyushu-u.ac.jp/ja/research.html)



# P.S. 追加情報

**理論通りの「厳密なMDL」を計算しようとすると、計算コストは爆発的に高くなります。**

グラフ全体の記述長 $L(G)$ を、ノードを1つ削除するたびに再計算していたら、Kuzuのような高速なDBを使っても日が暮れてしまいます。

しかし、**「局所的な近似（Local MDL）」**と**「ベクトルによる代用」**を行えば、Go言語とKuzuの環境で十分に実用的な速度で実装可能です。その「現実的な落とし込み方」を解説します。

### 1. なぜコストが高すぎるのか（厳密解の罠）
教科書的なMDLでは、あるノードを削除した際の影響を「グラフ全体」で評価します。
*   **計算**: ノードAを削除 $\to$ 他の全ノード間のパスや分布への影響を計算 $\to$ 圧縮率の変化を算出。
*   **計算量**: $O(N^2)$ や $O(N^3)$ になりがちで、数百万ノード規模では不可能です。

### 2. 現実的な解決策：局所MDL（Local MDL）
「あるノードの削除が、**その近傍（隣のノードたち）の記述**にどう影響するか」だけを見ます。これなら計算量は $O(1)$ （近傍ノード数に依存）で済みます。

#### Kuzu + Go での実装ロジック
KuzuはCypherクエリとベクトル演算が高速なので、これを活かします。

**判定式（MDLの超近似版）**:
$$ \text{削除スコア} = \underbrace{\text{ストレージコスト削減量}}_{L(M)\text{の減少}} - \underbrace{\text{情報の復元困難度}}_{L(D|M)\text{の増加}} $$

これを具体的に以下の手順で計算します。

#### 手順 A: コスト削減量（定数でOK）
1ノード、1エッジを削除することで減るデータ量は、ほぼ一定です。
*   例: ノード1個 = 100コスト、エッジ1本 = 10コスト と定義してしまいます。
*   次数が多いノードほど、削除時のコスト削減効果（エッジも消えるため）は高くなります。

#### 手順 B: 情報の復元困難度（ここをベクトルで代用する）
ここがMDLの肝ですが、複雑な確率計算の代わりに**「ベクトル類似度」**を使います。
*   **考え方**: 「そのノードの情報は、隣のノードたちの情報の平均値（または代表値）でどれくらい近似できるか？」
*   **実装**:
    1.  ターゲットノード $n$ の埋め込みベクトル $V_n$ を取得。
    2.  隣接ノード群のベクトル平均 $V_{neighbors}$ を計算。
    3.  **類似度が高い** $\to$ 「隣を見ればだいたいわかる」 $\to$ **復元容易（削除してOK）**
    4.  **類似度が高い** $\to$ 「周りと全然違う」 $\to$ **復元困難（特異点なので残す）**

$$ \text{復元困難度} \approx 1 - \text{CosineSimilarity}(V_n, V_{neighbors}) $$

### 3. 具体的な処理フロー（バッチ処理）

毎回全ノードを走査するのではなく、**「削除候補（Candidates）」**を絞ってからMDL判定にかけます。

1.  **一次フィルタ（高速）**:
    *   GoプログラムでKuzuにクエリを投げ、以下の条件のノードIDだけ取得します。
    *   条件: `孤立している OR 次数が低い` AND `最終アクセスが古い`
    *   これはインデックスが効くので一瞬です。
2.  **二次判定（近似MDL）**:
    *   取得した候補ノードに対してのみ、Goの並列処理（Goroutine）で上記の「ベクトル比較」を行います。
    *   Kuzuはベクトル検索が速いので、隣接ノードのベクトルを引いてきて計算するのも十分高速です。
3.  **削除実行**:
    *   スコアが閾値を超えたものだけを `DETACH DELETE` します。

### 結論
厳密な情報理論の式を解くのではなく、**「MDLの哲学（圧縮効率）を、ベクトル類似度という安い計算でシミュレーションする」**のが正解です。

これなら、数百万ノードあっても、夜間のバッチ処理などで十分に「賢い掃除」が可能になります。

### 引用
（MDLの局所的な適用や、近似アルゴリズムによる効率化の文脈に基づきます）[1][2][3]

[1](https://www.jstage.jst.go.jp/article/essfr/10/3/10_186/_article/-char/ja/)
[2](https://qiita.com/F-ridge/items/d67332ae1b0627b14f07)
[3](https://ibisml.org/archive/ibisml001/2010_IBISML01_Hirai.pdf)